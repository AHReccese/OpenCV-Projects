{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuestionOne\n",
    "## ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% adding libraris\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#%% Question one\n",
    "\n",
    "# loading main images...\n",
    "im_template = cv2.imread('template.jpg')\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "# showing main Images...\n",
    "cv2.imshow('mainTemplate',im_template)\n",
    "cv2.imshow('mainImage',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# initializing ORB\n",
    "orb = cv2.ORB_create()\n",
    "kp_t, des_t = orb.detectAndCompute(im_template, None)\n",
    "kp_i, des_i = orb.detectAndCompute(image, None)\n",
    "\n",
    "# matcher to draw matching :)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des_t, des_i)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "# Note You can use all found matches,but if you\n",
    "# draw all of them,the output would be a real mess!\n",
    "# so I rather to draw some of them \n",
    "# matching_result = cv2.drawMatches(im_template, kp_t, image, kp_i, matches, None, flags=2) -> draws all matches.\n",
    "matching_result = cv2.drawMatches(im_template, kp_t, image, kp_i, matches[:50], None, flags=2)\n",
    "\n",
    "# leftKeyPoints & rightKeyPoints & matching \n",
    "cv2.imshow('leftKeypoints',cv2.drawKeypoints(im_template,kp_t,None))\n",
    "cv2.imshow('rightKeypoints',cv2.drawKeypoints(image,kp_i,None))\n",
    "cv2.imshow(\"Matching\", matching_result)\n",
    "\n",
    "# saving results ...\n",
    "cv2.imwrite('leftKeypoints.jpg',cv2.drawKeypoints(im_template,kp_t,None))\n",
    "cv2.imwrite('rightKeypoints.jpg',cv2.drawKeypoints(image,kp_i,None))\n",
    "cv2.imwrite('matched.jpg',matching_result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT(AKAZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# loading main images...\n",
    "im_template = cv2.imread('template.jpg')\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "# showing main Images...\n",
    "cv2.imshow('mainTemplate',im_template)\n",
    "cv2.imshow('mainImage',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# initializing AKAZE\n",
    "akaze = cv2.AKAZE_create()\n",
    "kp_t, des_t = akaze.detectAndCompute(im_template, None)\n",
    "kp_i, des_i = akaze.detectAndCompute(image, None)\n",
    "\n",
    "# matcher to draw matching :)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des_t, des_i)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "# Note You can use all found matches,but if you\n",
    "# draw all of them,the output would be a real mess!\n",
    "# so I rather to draw some of them \n",
    "# matching_result = cv2.drawMatches(im_template, kp_t, image, kp_i, matches, None, flags=2) -> draws all matches.\n",
    "matching_result = cv2.drawMatches(im_template, kp_t, image, kp_i, matches[:50], None, flags=2)\n",
    "\n",
    "# leftKeyPoints & rightKeyPoints & matching \n",
    "cv2.imshow('leftKeypoints',cv2.drawKeypoints(im_template,kp_t,None))\n",
    "cv2.imshow('rightKeypoints',cv2.drawKeypoints(image,kp_i,None))\n",
    "cv2.imshow(\"Matching\", matching_result)\n",
    "\n",
    "# saving results ...\n",
    "cv2.imwrite('leftKeypoints.jpg',cv2.drawKeypoints(im_template,kp_t,None))\n",
    "cv2.imwrite('rightKeypoints.jpg',cv2.drawKeypoints(image,kp_i,None))\n",
    "cv2.imwrite('matched.jpg',matching_result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuestionTwo\n",
    "## 1-1.JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# loading and drawing images\n",
    "img = cv2.imread('1-1.JPG')\n",
    "cv2.imshow('1-1',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# resizedScales\n",
    "scale_percent = 50 # percent of original size\n",
    "height,width = int(img.shape[0] * scale_percent / 100),int(img.shape[1] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# resizing\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "points = np.zeros((4,2),np.int)\n",
    "\n",
    "# source and destination \n",
    "src_points = np.array([\n",
    "       [470, 490],\n",
    "       [800, 540],\n",
    "       [360, 590],\n",
    "       [760, 670]\n",
    "])\n",
    "\n",
    "dst_points = np.array([\n",
    "       [300,100],\n",
    "       [300,450],\n",
    "       [50,100],\n",
    "       [50,450]\n",
    "])\n",
    "\n",
    "# finding homographyMatrix\n",
    "M,mask = cv2.findHomography(src_points, dst_points)\n",
    "dst = cv2.warpPerspective(img,M,(700, 600))\n",
    "\n",
    "# drawing\n",
    "cv2.imwrite('TopView.jpg',dst)\n",
    "cv2.imshow(\"TopView.jpg\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2.JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# loading and drawing images\n",
    "img = cv2.imread('1-2.JPG')\n",
    "cv2.imshow('1-1',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# resizedScales\n",
    "scale_percent = 50 # percent of original size\n",
    "height,width = int(img.shape[0] * scale_percent / 100),int(img.shape[1] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# resizing\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "points = np.zeros((4,2),np.int)\n",
    "\n",
    "# source and destination \n",
    "src_points = np.array([\n",
    "       [540, 390],\n",
    "       [300, 420],\n",
    "       [350, 680],\n",
    "       [720, 600]\n",
    "])\n",
    "    \n",
    "dst_points = np.array([\n",
    "       [0,0],\n",
    "       [0,300],\n",
    "       [600,300],\n",
    "       [600,0]\n",
    "])\n",
    "\n",
    "# finding homographyMatrix\n",
    "M, mask = cv2.findHomography(src_points, dst_points)\n",
    "dst = cv2.warpPerspective(img,M,(650,325))\n",
    "cv2.imwrite('TopView.jpg',dst)\n",
    "\n",
    "# drawing\n",
    "cv2.imshow(\"TopView.jpg\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Three\n",
    "## 2-1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# flags & counters.\n",
    "counter = 0\n",
    "counter_temp = 0\n",
    "\n",
    "# loading and drawing images\n",
    "img = cv2.imread('2-1.jpg')\n",
    "img_original = cv2.imread('2-1.jpg')\n",
    "wrapper = cv2.imread('2-3.jpg')\n",
    "\n",
    "# resizedScales\n",
    "scale_percent = 30 # percent of original size\n",
    "height,width = int(img.shape[0] * scale_percent / 100),int(img.shape[1] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# resizing\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "img_original = cv2.resize(img_original, dim, interpolation = cv2.INTER_AREA)\n",
    "points = np.zeros((4,2),np.int)\n",
    "\n",
    "def mousePoints(event,x,y,flags,params):\n",
    "    global counter #we need to use it as counter in every parts\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points[counter] = x,y\n",
    "        counter = counter + 1\n",
    "        print(points)\n",
    "        \n",
    "\n",
    "finalImage = np.zeros(img.shape,np.uint8)\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", mousePoints)\n",
    "    \n",
    "while True:\n",
    "    if counter == 4:\n",
    "        # frame is selected,close mainImage\n",
    "        if counter_temp ==0:\n",
    "            cv2.destroyAllWindows()\n",
    "            counter_temp = 1\n",
    "        \n",
    "        # getting configs\n",
    "        height, width,_ = img.shape\n",
    "        height_t, width_t,_ = wrapper.shape\n",
    "        \n",
    "        # getting source and destination frames\n",
    "        pts1 = np.float32([points[0],points[1],points[2],points[3]])\n",
    "        pts2 = np.float32([[0,0],[width_t,0],[0,height_t],[width_t,height_t]])\n",
    "        \n",
    "        # getting transformMatrix\n",
    "        matrix = cv2.getPerspectiveTransform(pts2,pts1)\n",
    "        # positioning Wrapper in the frame.\n",
    "        overlay = cv2.warpPerspective(wrapper,matrix,(width,height))\n",
    "        \n",
    "        # filling the FinalResult\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if overlay[i,j,0] == 0:\n",
    "                    finalImage[i,j,:]  = img_original[i,j,:]\n",
    "                else:\n",
    "                    finalImage[i,j,:]  = overlay[i,j,:]\n",
    "                   \n",
    "       \n",
    "        cv2.imshow(\"image\", finalImage)               \n",
    "        \n",
    "    # drawing Circles\n",
    "    for x in range (0,counter):\n",
    "        cv2.circle(img,(points[x][0],points[x][1]),3,(0,255,0),cv2.FILLED)\n",
    "    if counter != 4:\n",
    "        cv2.imshow(\"image\", img)\n",
    "        \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('e'):\n",
    "        break\n",
    "        \n",
    "cv2.imwrite('mainImage.jpg',img)\n",
    "cv2.imwrite('Wrapped.jpg',finalImage)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# flags & counters.\n",
    "counter = 0\n",
    "counter_temp = 0\n",
    "\n",
    "# loading and drawing images\n",
    "img = cv2.imread('2-2.jpg')\n",
    "img_original = cv2.imread('2-2.jpg')\n",
    "wrapper = cv2.imread('2-3.jpg')\n",
    "\n",
    "# resizedScales\n",
    "scale_percent = 30 # percent of original size\n",
    "height,width = int(img.shape[0] * scale_percent / 100),int(img.shape[1] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# resizing\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "img_original = cv2.resize(img_original, dim, interpolation = cv2.INTER_AREA)\n",
    "points = np.zeros((4,2),np.int)\n",
    "\n",
    "def mousePoints(event,x,y,flags,params):\n",
    "    global counter #we need to use it as counter in every parts\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points[counter] = x,y\n",
    "        counter = counter + 1\n",
    "        print(points)\n",
    "        \n",
    "\n",
    "finalImage = np.zeros(img.shape,np.uint8)\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", mousePoints)\n",
    "    \n",
    "while True:\n",
    "    if counter == 4:\n",
    "        # frame is selected,close mainImage\n",
    "        if counter_temp ==0:\n",
    "            cv2.destroyAllWindows()\n",
    "            counter_temp = 1\n",
    "        \n",
    "        # getting configs\n",
    "        height, width,_ = img.shape\n",
    "        height_t, width_t,_ = wrapper.shape\n",
    "        \n",
    "        # getting source and destination frames\n",
    "        pts1 = np.float32([points[0],points[1],points[2],points[3]])\n",
    "        pts2 = np.float32([[0,0],[width_t,0],[0,height_t],[width_t,height_t]])\n",
    "        \n",
    "        # getting transformMatrix\n",
    "        matrix = cv2.getPerspectiveTransform(pts2,pts1)\n",
    "        # positioning Wrapper in the frame.\n",
    "        overlay = cv2.warpPerspective(wrapper,matrix,(width,height))\n",
    "        \n",
    "        # filling the FinalResult\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if overlay[i,j,0] == 0:\n",
    "                    finalImage[i,j,:]  = img_original[i,j,:]\n",
    "                else:\n",
    "                    finalImage[i,j,:]  = overlay[i,j,:]\n",
    "                   \n",
    "       \n",
    "        cv2.imshow(\"image\", finalImage)               \n",
    "        \n",
    "    # drawing Circles\n",
    "    for x in range (0,counter):\n",
    "        cv2.circle(img,(points[x][0],points[x][1]),3,(0,255,0),cv2.FILLED)\n",
    "    if counter != 4:\n",
    "        cv2.imshow(\"image\", img)\n",
    "        \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('e'):\n",
    "        break\n",
    "        \n",
    "cv2.imwrite('mainImage.jpg',img)\n",
    "cv2.imwrite('Wrapped.jpg',finalImage)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuestionFour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def thresholding(matches,threshold):\n",
    "    selected = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < threshold*n.distance:\n",
    "            selected.append(m)\n",
    "    return selected\n",
    "\n",
    "# removing Black parts\n",
    "def cropping(frame):\n",
    "    \n",
    "    # if \"np.sum(frame[sth:] or frame[:sth])\" is zero so this line\n",
    "    # is completely Black so lets remove it.\n",
    "    \n",
    "    # top horizontal line\n",
    "    if not np.sum(frame[0]):\n",
    "        #removingBlackPart\n",
    "        return cropping(frame[1:])\n",
    "    \n",
    "    # bottom horizontal line\n",
    "    if not np.sum(frame[-1]):\n",
    "        return cropping(frame[:-2])\n",
    "\n",
    "    # left vertical line\n",
    "    if not np.sum(frame[:,0]):\n",
    "        return cropping(frame[:,1:])\n",
    "\n",
    "    # right vertical line\n",
    "    if not np.sum(frame[:,-1]):\n",
    "        return cropping(frame[:,:-2])\n",
    "    \n",
    "    return frame\n",
    "        \n",
    "# loading and drawing images\n",
    "img2 = cv2.imread('3-1.jpeg')\n",
    "img1 = cv2.imread('3-2.jpeg')\n",
    "\n",
    "# resizedScales\n",
    "scale_percent = 80 # percent of original size\n",
    "height,width =  int(img1.shape[0] * scale_percent / 100),int(img1.shape[1] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# resizing the images\n",
    "img1= cv2.resize(img1, dim, interpolation = cv2.INTER_AREA)\n",
    "img2 = cv2.resize(img2, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# initializing AKAZE\n",
    "akaze = cv2.AKAZE_create()\n",
    "kpts1, desc1 = akaze.detectAndCompute(img1, None)\n",
    "kpts2, desc2 = akaze.detectAndCompute(img2, None)\n",
    "\n",
    "# leftKeyPoints & rightKeyPoints\n",
    "cv2.imshow('leftKeypoints',cv2.drawKeypoints(img1,kpts1,None))\n",
    "cv2.imshow('rightKeypoints',cv2.drawKeypoints(img2,kpts2,None))\n",
    "# writing key Values \n",
    "cv2.imwrite('leftKeypoints.jpg',cv2.drawKeypoints(img1,kpts1,None))\n",
    "cv2.imwrite('rightKeypoints.jpg',cv2.drawKeypoints(img2,kpts2,None))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# matcher to draw matching :)\n",
    "match = cv2.BFMatcher()\n",
    "matches = match.knnMatch(desc2,desc1,k=2)\n",
    "    \n",
    "# adding threshold to KeyPoints\n",
    "selected = thresholding(matches,0.35)\n",
    "        \n",
    "# setting Marker with red Colour for drawing Matches\n",
    "draw_params = dict(matchColor = (255,0,0),singlePointColor = None,flags = 2)\n",
    "img3 = cv2.drawMatches(img2,kpts2,img1,kpts1,selected,None,**draw_params)\n",
    "# drawing matches \n",
    "cv2.imshow(\"Matches\", img3)\n",
    "# saving matches\n",
    "cv2.imwrite(\"Matches.jpg\", img3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# reverse connecting\n",
    "matches = match.knnMatch(desc1,desc2,k=2)\n",
    "selected = thresholding(matches,0.35)\n",
    "\n",
    "# source & dest Keypoints in pictures(among thresholded matches)\n",
    "src_pts = np.float32([ kpts1[m.queryIdx].pt for m in selected ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kpts2[m.trainIdx].pt for m in selected ]).reshape(-1,1,2)\n",
    "\n",
    "# finding homographyMatrix\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "# warping ...\n",
    "dst = cv2.warpPerspective(img1,M,(img2.shape[1] + img1.shape[1], 2*img2.shape[0]))\n",
    "dst[0:img2.shape[0],0:img2.shape[1]] = img2\n",
    "\n",
    "\n",
    "cv2.imshow(\"stitchedCrop\", cropping(dst))\n",
    "cv2.imwrite(\"stitchedCrop.jpg\", cropping(dst))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuestionFive\n",
    "## part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# loading images\n",
    "img1 = cv2.imread('4-1.jpg')\n",
    "img2 = cv2.imread('4-2.jpg')\n",
    "\n",
    "def drawLeftCorners(img):\n",
    "    # finding chessBoardCorners\n",
    "    retval,chessBoardCorners = cv2.findChessboardCorners(img,(7,8))\n",
    "    numOfCorners = len(chessBoardCorners)\n",
    "\n",
    "    result = np.ndarray.copy(img)\n",
    "    # drawing\n",
    "    for i in range(numOfCorners):\n",
    "        points = chessBoardCorners[i]\n",
    "        result = cv2.circle(result,(points[0][0],points[0][1]),3,(0,0,255),cv2.FILLED)\n",
    "    return result,chessBoardCorners\n",
    "\n",
    "\n",
    "def drawRightCorners(img):\n",
    "    # finding chessBoardCorners\n",
    "    retval,chessBoardCorners = cv2.findChessboardCorners(img,(6,5))\n",
    "    numOfCorners = len(chessBoardCorners)\n",
    "\n",
    "    result = np.ndarray.copy(img)\n",
    "    # drawing\n",
    "    for i in range(numOfCorners):\n",
    "        points = chessBoardCorners[i]\n",
    "        result = cv2.circle(result,(points[0][0],points[0][1]),3,(0,0,255),cv2.FILLED)\n",
    "    return result,chessBoardCorners\n",
    "\n",
    "\n",
    "\n",
    "img1Left,pts1Left = drawLeftCorners(img1)\n",
    "img1Right,pts1Right = drawRightCorners(img1)\n",
    "\n",
    "img2Left,pts2Left = drawLeftCorners(img2)\n",
    "img2Right,pts2Right = drawRightCorners(img2)\n",
    "\n",
    "cv2.imshow(\"FirstImageLeftCorners.jpg\", img1Left)\n",
    "cv2.imshow(\"FirstImageRightCorners.jpg\", img1Right)\n",
    "\n",
    "cv2.imwrite(\"FirstImageLeftCorners.jpg\", img1Left)\n",
    "cv2.imwrite(\"FirstImageRightCorners.jpg\", img1Right)\n",
    "\n",
    "cv2.imshow(\"SecondImageLeftCorners.jpg\", img2Left)\n",
    "cv2.imshow(\"SecondImageRightCorners.jpg\", img2Right)\n",
    "\n",
    "cv2.imwrite(\"SecondImageLeftCorners.jpg\", img2Left)\n",
    "cv2.imwrite(\"SecondImageRightCorners.jpg\", img2Right)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2,3\n",
    "### warning: before running you should first run part1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "firstImageAllCorners = np.row_stack((pts1Left,pts1Right))\n",
    "secondImageAllCorners = np.row_stack((pts2Left,pts2Right))\n",
    "\n",
    "#finding fundamental matrix\n",
    "fundamental = cv2.findFundamentalMat(firstImageAllCorners,\n",
    "                                     secondImageAllCorners,\n",
    "                                     cv2.FM_LMEDS)\n",
    "\n",
    "F = fundamental[0]\n",
    "\n",
    "# extracting epipolar line with stereo\n",
    "img3 = cv2.imread('4-3.jpg')\n",
    "img4 = cv2.imread('4-4.jpg')\n",
    "consideredPoint = np.array([265,305])\n",
    "lines = cv2.computeCorrespondEpilines(consideredPoint.reshape(-1,1,2),2,F)\n",
    "\n",
    "# this function is extracted from StackOverFlow :)\n",
    "# https://stackoverflow.com/questions/51089781/\n",
    "# how-to-calculate-an-epipolar-line-with-a-stereo-pair-of-images-in-python-opencv\n",
    "\n",
    "def drawLines(img1,img2,lines,pts2):\n",
    "    _,c,_ = img1.shape\n",
    "    r = lines.reshape(3)\n",
    "    color = (0,0,255)\n",
    "    x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "    x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "    img1 = cv2.line(img1, (x0,y0), (x1,y1), color,1)\n",
    "    img2 = cv2.circle(img2,tuple(pts2),5,color,-1)\n",
    "    return img1,img2\n",
    "\n",
    "img3,img4 = drawLines(img3,img4,lines,consideredPoint)\n",
    "\n",
    "cv2.imshow(\"Image4\",img4)\n",
    "cv2.imshow(\"Image3Lined\", img3)\n",
    "cv2.imwrite(\"Image4.jpg\", img4)\n",
    "cv2.imwrite(\"Image3Lined.jpg\", img3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 4\n",
    "### warning: before running you should first run part2,3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img3 = cv2.imread('4-3.jpg')\n",
    "img4 = cv2.imread('4-4.jpg')\n",
    "\n",
    "counter = 10\n",
    "\n",
    "def drawLines(img1,img2,lines,pts2):\n",
    "    global counter\n",
    "    _,c,_ = img1.shape\n",
    "    r = lines.reshape(3)\n",
    "    color = (counter,\n",
    "             randrange(counter + 1),\n",
    "             255 - randrange(counter%255 + 1))\n",
    "    \n",
    "    x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "    x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "    img1 = cv2.line(img1, (x0,y0), (x1,y1), color,1)\n",
    "    img2 = cv2.circle(img2,tuple(pts2),5,color,-1)\n",
    "    counter = (counter + 10 )%255\n",
    "    return img1,img2\n",
    "\n",
    "# it draws 4-3's lines in 4-4\n",
    "# change firstImageAllCorners to secondImageAllCorners\n",
    "# to draw 4-4's lines in 4-3.\n",
    "\n",
    "for i in range(len(firstImageAllCorners)): # or len(secondImageAllCorners),both are 86.\n",
    "    point = firstImageAllCorners[i,:,:] \n",
    "    lines = cv2.computeCorrespondEpilines(point.reshape(-1,1,2)\n",
    "                                          ,1,F)\n",
    "    img4,img3 = drawLines(img4,img3,lines,point.reshape(2))\n",
    "\n",
    "cv2.imshow(\"Image3\", img3)\n",
    "cv2.imshow(\"Image4Lined\", img4)\n",
    "cv2.imwrite(\"Image4Lined.jpg\", img4)\n",
    "cv2.imwrite(\"Image3.jpg\", img3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
